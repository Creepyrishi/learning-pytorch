{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7210d2",
   "metadata": {},
   "source": [
    "## Loading Dataset in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d71537-d7f8-4d41-9194-28566e379681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79039ae5-6ce5-438b-9cc0-8b2c5089938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0762, 0.2023, 0.4843],\n",
      "        [0.8552, 0.5819, 0.9306],\n",
      "        [0.0195, 0.9490, 0.5095],\n",
      "        [0.7226, 0.9338, 0.2665],\n",
      "        [0.2333, 0.0095, 0.8025],\n",
      "        [0.0247, 0.5006, 0.8099],\n",
      "        [0.7040, 0.2090, 0.6323],\n",
      "        [0.0022, 0.7018, 0.1988],\n",
      "        [0.3765, 0.0320, 0.4911],\n",
      "        [0.1608, 0.6095, 0.4241]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "a = torch.rand((10,3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce659bd-e49b-45cc-b6e7-ef27ed65a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681db083-ffc2-4a18-8cf4-23a2e3c3f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) tensor([[0.0762, 0.2023, 0.4843],\n",
      "        [0.8552, 0.5819, 0.9306],\n",
      "        [0.0195, 0.9490, 0.5095]])\n",
      "1) tensor([[0.7226, 0.9338, 0.2665],\n",
      "        [0.2333, 0.0095, 0.8025],\n",
      "        [0.0247, 0.5006, 0.8099]])\n",
      "1) tensor([[0.7040, 0.2090, 0.6323],\n",
      "        [0.0022, 0.7018, 0.1988],\n",
      "        [0.3765, 0.0320, 0.4911]])\n",
      "1) tensor([[0.1608, 0.6095, 0.4241]])\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(a, batch_size=3)\n",
    "\"\"\"\n",
    "This loads the whole dataset but in small chunks that can be used as mini-batches\n",
    "\"\"\"\n",
    "for i, data in enumerate(data):\n",
    "    print(f\"{1}) {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d146b",
   "metadata": {},
   "source": [
    "## Creating a custom inheritance of pytorch of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf34507-2ecf-46b8-840f-6c4e9f6b7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining 2 data set\n",
    "# We need to create a custom joinDataset class that inheritate Dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class joinDataset(Dataset):\n",
    "    \"\"\"\n",
    "    When we Create inheritance of Dataset class we need to have these 3 compulsory methods:\n",
    "    1. __init__\n",
    "    2. __len__\n",
    "    3. __getitem__\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84272d1e-c3b3-49af-8f10-4d3f032ba7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasets or tensors to join\n",
    "d1 = torch.rand((6,3)) # think this is feature dataset\n",
    "d2 = torch.rand((6)) # and this is target dataset\n",
    "\n",
    "dataset = joinDataset(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26756bd6-623e-44e0-8bfd-11d18346c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.8812, 0.9455, 0.1917]), tensor(0.3988))\n",
      "(tensor([0.8008, 0.0030, 0.2193]), tensor(0.4160))\n",
      "(tensor([0.1905, 0.7179, 0.4375]), tensor(0.4118))\n",
      "(tensor([0.6937, 0.7987, 0.8955]), tensor(0.6417))\n",
      "(tensor([0.5297, 0.1944, 0.1129]), tensor(0.1690))\n",
      "(tensor([0.8605, 0.7493, 0.7651]), tensor(0.7931))\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1008502-fa83-42c9-8898-1867708fe152",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1) # fixing the random seed so that the suffled dataset will contain same row no matter how many time I rerun \n",
    "data_set = DataLoader(dataset, batch_size= 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9810bb9a-14f6-46c4-9723-04b06466690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [tensor([[0.8812, 0.9455, 0.1917],\n",
      "        [0.8008, 0.0030, 0.2193]]), tensor([0.3988, 0.4160])]\n",
      "1. [tensor([[0.5297, 0.1944, 0.1129],\n",
      "        [0.6937, 0.7987, 0.8955]]), tensor([0.1690, 0.6417])]\n",
      "2. [tensor([[0.1905, 0.7179, 0.4375],\n",
      "        [0.8605, 0.7493, 0.7651]]), tensor([0.4118, 0.7931])]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(data_set):\n",
    "    print(f\"{i}. {batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235c3902-bdbe-42cf-84e4-de69322a3dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0. [tensor([[0.8812, 0.9455, 0.1917],\n",
      "        [0.5297, 0.1944, 0.1129]]), tensor([0.3988, 0.1690])]\n",
      "1. [tensor([[0.1905, 0.7179, 0.4375],\n",
      "        [0.8008, 0.0030, 0.2193]]), tensor([0.4118, 0.4160])]\n",
      "2. [tensor([[0.8605, 0.7493, 0.7651],\n",
      "        [0.6937, 0.7987, 0.8955]]), tensor([0.7931, 0.6417])]\n",
      "epoch 1\n",
      "0. [tensor([[0.8008, 0.0030, 0.2193],\n",
      "        [0.6937, 0.7987, 0.8955]]), tensor([0.4160, 0.6417])]\n",
      "1. [tensor([[0.1905, 0.7179, 0.4375],\n",
      "        [0.8812, 0.9455, 0.1917]]), tensor([0.4118, 0.3988])]\n",
      "2. [tensor([[0.5297, 0.1944, 0.1129],\n",
      "        [0.8605, 0.7493, 0.7651]]), tensor([0.1690, 0.7931])]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" For every epochs it the batchs will get suffled \"\"\"\n",
    "for epoch in range(2):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    for i, batch in enumerate(data_set):\n",
    "        print(f\"{i}. {batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5353f8c-ee6d-41cb-96bc-608f544ba17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
