{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0401d063-b93b-4c29-a0c8-0a7f26faf17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45909508-1e44-4762-83a9-31f7950cf4be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f06c3e-0cc6-4bfe-9805-2395614592bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# creating tensors from python array(list) and numpy array\n",
    "a = [1, 2, 3]\n",
    "b = np.array([4, 5, 6], dtype = np.int32)\n",
    "\n",
    "te_a = torch.tensor(a)\n",
    "te_b = torch.tensor(b)\n",
    "\n",
    "print(te_a)\n",
    "print(te_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa25bc7a-c4b8-40cb-a66b-0c14156a803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# creating a tensor with all element 1 \n",
    "te_c = torch.ones(size = (2, 3))\n",
    "print(te_c)\n",
    "print(te_c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e244fad-ba86-4b63-b009-100be9c3b370",
   "metadata": {},
   "source": [
    "- **Shape** is like a label on the outside of the box that tells you how many boxes are inside and how big they are.\n",
    "\n",
    "- **Size** is like counting the number of boxes you have in each size. So you can say \"I have 3 boxes that are big, and 4 boxes that are small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661a6806-28eb-444d-80ea-5d951f59db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# creating a tensor with all val 0 \n",
    "te_d = torch.zeros((1, 2))\n",
    "print(te_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e004e1-eeef-426d-a6dd-d216dffd0f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1244, 0.7860, 0.3895, 0.9390],\n",
      "        [0.1364, 0.7657, 0.6788, 0.5905],\n",
      "        [0.6626, 0.6404, 0.3048, 0.4547]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor with random value\n",
    "te_e = torch.rand((3,4))\n",
    "print(te_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fabc40-f1a9-439d-82b8-ff9bdc66be7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Transforming tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cf1da2-2441-423c-ac4b-02b710b13450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Transposing a tensor\n",
    "transposed_te_e = torch.transpose(input = te_e, dim0 = 0, dim1= 1)\n",
    "print(te_e.shape)\n",
    "print(transposed_te_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5c1a98-2408-4409-b7ce-fef76d7e0020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3799, 0.0516, 0.2182, 0.3438, 0.4388, 0.2983]],\n",
      "\n",
      "        [[0.5448, 0.2657, 0.4813, 0.8509, 0.7852, 0.3157]],\n",
      "\n",
      "        [[0.1413, 0.4893, 0.3113, 0.6023, 0.9086, 0.9579]],\n",
      "\n",
      "        [[0.3048, 0.3211, 0.7420, 0.6447, 0.7326, 0.3396]],\n",
      "\n",
      "        [[0.0608, 0.0896, 0.1625, 0.6864, 0.9451, 0.6563]]])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping a tensor\n",
    "te_f = torch.rand(30) #from 0-1\n",
    "reshaped_te_f = te_f.reshape((5,1,6)) # all dimensions should multiply to previous one. 5*1*6 = 30\n",
    "print(reshaped_te_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820134aa-57ae-41e8-8d4c-7a2c80703bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 6])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Squeezing the tensors0\n",
    "\"\"\" Squeezing mean:  we we have multiple demntioned tensor and some of dimention is 1, this method will get rid of that dimension., except for the dimention is first or .last of that  \n",
    "like (3,4,2,1,3,1) --> (3,4,2,3, 1)\"\"\"\n",
    "sqe_reshaped_te_f = reshaped_te_f.squeeze()\n",
    "print(reshaped_te_f.shape)\n",
    "print(sqe_reshaped_te_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c7e64-6e4d-48f5-b294-86423c4116f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Mathematical operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40e0223-7b95-4ca4-8c39-e22d64141c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 tensor to do operations on\n",
    "\n",
    "x = torch.rand(5,6) - 1\n",
    "y = torch.normal(mean = 0, std =2.5, size = (5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461c7c1b-0de5-4807-b3ae-4fefc84199ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3524, -0.2100,  0.7393,  0.0821,  0.6049,  0.4020],\n",
      "        [ 0.2451, -3.8007, -1.1096, -2.0882,  1.0515, -0.3543],\n",
      "        [-0.0864,  0.4024, -0.2634, -1.2567, -1.2861,  0.5221],\n",
      "        [-0.1277,  0.1112,  2.4232,  0.8659, -5.6495,  1.7745],\n",
      "        [ 0.4224,  0.8789, -2.1585,  0.0886, -1.1239, -0.1789]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "\"\"\"\n",
    "Both tensors must have the same number of dimensions or one tensor must have a dimension\n",
    "of size 1 that can be broadcasted to match the other tensor's shape.\n",
    "\"\"\"\n",
    "t3 = torch.multiply(x, y)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94f0b45-1cbb-482d-86a0-91141685e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4951, -1.0094, -0.3280, -0.1004, -0.3452])\n",
      "tensor([ 2.9708, -6.0563, -1.9681, -0.6025, -2.0714])\n",
      "tensor([0.5446, 1.7444, 0.7873, 2.8864, 1.1134])\n"
     ]
    }
   ],
   "source": [
    "# Some more\n",
    "print(torch.mean(t3, axis=1))\n",
    "print(torch.sum(t3, axis=1))\n",
    "print(torch.std(t3, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24704afd-0dcc-44c6-9487-4c0b2487567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9708, -0.4243, -1.8371, -2.8036, -0.4817],\n",
      "        [ 4.3973, -6.0563, -3.5255, -1.7716, -1.7308],\n",
      "        [ 0.3145, -5.6690, -1.9681, -2.6063,  0.1925],\n",
      "        [ 6.9845, -7.0363, -2.6366, -0.6025, -2.5203],\n",
      "        [ 3.9466, -3.9501,  0.2167,  0.1466, -2.0714]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "t4 = torch.matmul(x, torch.transpose(y, 0, 1)) \n",
    "\"\"\"\n",
    "I have transposed as y becasue x and y both have same dimention and in order to do matrix , we need to match column of first to row of second\n",
    "\"\"\"\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d8762e0-343a-4ee6-a331-8422c12c3eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-7.7276)\n"
     ]
    }
   ],
   "source": [
    "# dot multiplication\n",
    "\"\"\"\n",
    "We can only do dot multiplication in 1d arrays so we have to use either .reshape(-1) or .faltten() convert the matrix in 1d before dot product\n",
    "\"\"\"\n",
    "t5 = torch.dot(x.flatten(), y.flatten()) \n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec941d6-6ae1-4dd7-95f0-8b882b7b1b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Little more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0928723d-07e2-4482-9c22-ff959c42b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 : tensor([0.7648, 0.3958, 0.0978, 0.3106])\n",
      "Chunk 1 : tensor([0.2060, 0.7780, 0.7123, 0.3043])\n",
      "Chunk 2 : tensor([0.0859, 0.7132])\n"
     ]
    }
   ],
   "source": [
    "# Chunking\n",
    "\"\"\"\n",
    "Chunk divide the give tensor to the given number of chunk and in given dimension. we can not specify that second chunch shoud have particular number of\n",
    "element rather it is calculated by diving the number of element along the given dimention by numbet of needed chunk some time if not exactly divisible \n",
    "last chuck may have fewer element that expected\n",
    "\"\"\"\n",
    "t6 = torch.rand(10)\n",
    "chunks = torch.chunk(t6, 3, dim=0)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i} : {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b492044-a0af-46d1-8cab-ecf2ab991954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0 : tensor([0.7648, 0.3958, 0.0978])\n",
      "split 1 : tensor([0.3106, 0.2060])\n",
      "split 2 : tensor([0.7780, 0.7123, 0.3043, 0.0859, 0.7132])\n"
     ]
    }
   ],
   "source": [
    "# Splitting\n",
    "\"\"\"\n",
    "Split is simmilar to chunk just we can give numnber of elements we want to have in each chunk\n",
    "\"\"\"\n",
    "splits = torch.split(t6, [3, 2, 5], dim = 0) # [3, 2, 5] this should add to original dimention 10\n",
    "for i, split in enumerate(splits):\n",
    "    print(f\"split {i} : {split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586df38-d8bc-46ba-8868-2bb43b3209d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
